A Next.js application that lets users upload any PDF and instantly start chatting with it.
Ask questions, get summaries, extract metadata (title, author, keywords, etc.) and jump to cited pages in the original document â€“ all in a clean, responsive interface.
## Getting Started

First, run the development server:

npm install
npm run dev

```

Open [http://localhost:3000](http://localhost:3000) with your browser to see the result.

This is the project structure

pdf-chat-assistant/
â”œâ”€ app/
â”‚  â”œâ”€ api/
â”‚  â”‚  â”œâ”€ chat/route.ts        # POST /api/chat â€“ ask questions
â”‚  â”‚  â”œâ”€ pdf/[pdfId]/route.ts # GET / POST PDF metadata & processing
â”‚  â”‚  â””â”€ upload/route.ts      # POST /api/upload â€“ file upload endpoint
â”‚  â”œâ”€ components/
â”‚  â”‚  â”œâ”€ Chatbox.tsx          # Main chat UI with suggestions
â”‚  â”‚  â”œâ”€ PdfViewer.tsx        # React-PDF viewer + page navigator
â”‚  â”‚  â”œâ”€ UploadArea.tsx       # Drag-and-drop upload card
â”‚  â”‚  â””â”€ ...
â”‚  â”œâ”€ context/page.context.tsx# Global state (pdfId, pageNumber, etc.)
â”‚  â””â”€ page.tsx                # Entry point â€“ handles upload / chat layout
â”œâ”€ utils/
â”‚  â””â”€ langchainPdf.ts         # LangChain logic (split, embed, answer)
â”œâ”€ public/uploads/            # Uploaded PDFs (auto-created)
â””â”€ ...



## Features

Upload PDFs and extract metadata (title, author, summary, etc.)

Semantic search across the document with vector embeddings

Natural chat interface with sources + citations

Interactive viewer: citations link to the right page in the PDF

Built with Next.js App Router (frontend + backend in one)

âš™ï¸ How it Works

ğŸ“ Processing

PDF is loaded with PDFLoader

Split into 1000-token chunks (200 overlap)

Embedded via OpenAI text-embedding-ada-002

Stored in an in-memory vector store (MemoryVectorStore)

Metadata (title, author, summary, etc.) extracted using GPT-3.5 prompt

ğŸ’¬ Chat

Metadata questions (e.g. â€œtitle?â€, â€œauthor?â€) â†’ answered instantly without search

Content questions â†’ vector similarity search â†’ retrieval chain â†’ GPT generates an answer with page citations

ğŸ“– Viewer

react-pdf renders the document

Citations and buttons sync the viewer to the correct page via global context

## âš¡ Optimizations
ğŸ”¹ Performance

Smarter chunking â†’ adaptive splitting by semantic paragraphs (500â€“1500 tokens depending on PDF type).

Caching embeddings â†’ hash PDFs and skip re-embedding if already stored.

Streaming answers â†’ show tokens as they arrive for faster perceived response.

ğŸ”¹ Cost

Cheaper models for metadata â†’ gpt-3.5-turbo for title/author, higher models only for deep Q&A.

Token-efficient retrieval â†’ limit context to top 3â€“5 relevant chunks (MMR to avoid redundancy).

Batch embedding requests â†’ embed multiple chunks per API call to reduce request overhead.

ğŸ”¹ User Experience

Prefetch metadata â†’ show title, author, and summary instantly while embeddings process in the background.

Citation highlighting â†’ highlight exact answer sentences in PDF viewer, not just page numbers.

Progressive loading â†’ process first N pages immediately, allow questions on them while rest of PDF embeds.